{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study - The Current\n",
    "\n",
    "* The Current is an alternative radio station\n",
    "* We will pull information about the play list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0 - Inspect the following page\n",
    "\n",
    "* Song title\n",
    "* Artist\n",
    "* Play time\n",
    "* Day, date, period (am/pm)\n",
    "\n",
    "http://www.thecurrent.org/playlist/2014-01-01/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import modules here\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from composablesoup import find, find_all, get_text, has_attr\n",
    "from composable.sequence import slice, head\n",
    "from composable.strict import map, filter\n",
    "from composable.string import replace, split\n",
    "from composable import from_toolz as tlz\n",
    "from composable import pipeable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read in the page here\n",
    "s = requests.Session()\n",
    "r = s.get('http://www.thecurrent.org/playlist/2014-01-01/01')\n",
    "current = BeautifulSoup(r.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Pull off the period of the day (am/pm)\n",
    "\n",
    "Pull out the \"am\"/\"pm\"\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Search the soup\n",
    "    1. There should be one item returned\n",
    "4. Use soup\\string methods to pull out the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Creating a function to strip whitespace\n",
    "strip = pipeable(lambda s: s.strip())\n",
    "\n",
    "# Returning am/pm\n",
    "(current\n",
    "    >> find('span', attrs = {'class' : \"hour-header open\"})\n",
    "    >> get_text\n",
    "    >> strip\n",
    "    >> replace('\\n', '')\n",
    "    >> split(' ')\n",
    "    >> tlz.get(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_period = pipeable(lambda soup: soup\n",
    "                    >> find('span', attrs = {'class' : \"hour-header open\"})\n",
    "                    >> get_text\n",
    "                    >> strip\n",
    "                    >> replace('\\n', '')\n",
    "                    >> split(' ')\n",
    "                    >> tlz.get(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Pull off DJ\n",
    "\n",
    "Use a similar process to pull off the DJ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Jade'"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "(current\n",
    "    >> find('h5', attrs = {'class' : \"currentDj\"})\n",
    "    >> get_text\n",
    "    >> replace('DJ: ', '')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dj = lambda soup: (soup\n",
    "    >> find('h5', attrs = {'class' : \"currentDj\"})\n",
    "    >> get_text\n",
    "    >> replace('DJ: ', '')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Pull out the day of the week\n",
    "\n",
    "* Pull out the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Wednesday'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Returning day of week\n",
    "(current\n",
    "    >> find('a', attrs = {'class' : \"start-picker\"})\n",
    "    >> get_text\n",
    "    >> strip\n",
    "    >> split(',')\n",
    "    >> tlz.get(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Wednesday'"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "get_day = pipeable(lambda soup: (soup\n",
    "                >> find('a', attrs = {'class' : \"start-picker\"})\n",
    "                >> get_text\n",
    "                >> strip\n",
    "                >> split(',')\n",
    "                >> tlz.get(0)\n",
    "            )\n",
    ")\n",
    "current >> get_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title of each song\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Use `find_all` to make a list of all relevant tags\n",
    "4. Pull off an example case\n",
    "5. Write a function to pull out the title\n",
    "6. Write a single pipe to convert the original soup into a list of titles. \n",
    "7. Verify you have the right number of titles.\n",
    "8. Package the pipe in a function named `get_title`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Holy Roller',\n",
       " 'Kingdom of Rust',\n",
       " 'Black Dog',\n",
       " 'Turn It Around',\n",
       " 'Flavor of the Month',\n",
       " 'Potential Wife',\n",
       " '24 Hours',\n",
       " \"Who's Gonna Shoe Your Pretty Little Feet?\",\n",
       " 'Marigold',\n",
       " 'High Road',\n",
       " 'The Vampyre Of Time and Memory',\n",
       " 'Valerie Plame',\n",
       " 'Morning Song',\n",
       " '(You Will) Set The World On Fire',\n",
       " 'Sixteen Saltines',\n",
       " 'Wave of Mutilation']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "(current\n",
    ">> find_all('h5', attrs={'class':'title'})\n",
    ">> map(get_text)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Holy Roller',\n",
       " 'Kingdom of Rust',\n",
       " 'Black Dog',\n",
       " 'Turn It Around',\n",
       " 'Flavor of the Month',\n",
       " 'Potential Wife',\n",
       " '24 Hours',\n",
       " \"Who's Gonna Shoe Your Pretty Little Feet?\",\n",
       " 'Marigold',\n",
       " 'High Road',\n",
       " 'The Vampyre Of Time and Memory',\n",
       " 'Valerie Plame',\n",
       " 'Morning Song',\n",
       " '(You Will) Set The World On Fire',\n",
       " 'Sixteen Saltines',\n",
       " 'Wave of Mutilation']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "get_title = pipeable(lambda soup: (soup\n",
    "                    >> find_all('h5', attrs={'class':'title'})\n",
    "                    >> map(get_text)\n",
    "                    ))\n",
    "current >> get_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull off the name of the artist\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Use `find_all` to make a list of all relevant tags\n",
    "4. Pull off an example case\n",
    "5. Write a function to pull out the artist\n",
    "6. Write a single pipe to convert the original soup into a list of artists. \n",
    "7. Verify you have the right number of artists.\n",
    "8. Package the pipe in a function named `get_artist`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Thao and The Get Down Stay Down',\n",
       " 'Doves',\n",
       " 'Frankie Lee',\n",
       " 'Lucius',\n",
       " 'The Posies',\n",
       " 'Strange Names',\n",
       " 'Sky Ferreira',\n",
       " 'Billie Joe and Norah',\n",
       " 'J. Roddy Walston and The Business',\n",
       " 'Cults',\n",
       " 'Queens of the Stone Age',\n",
       " 'The Decemberists',\n",
       " 'The Avett Brothers',\n",
       " 'David Bowie',\n",
       " 'Jack White',\n",
       " 'Pixies']"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "get_artist = pipeable(lambda soup: (soup\n",
    "                    >> find_all('h5', attrs={'class':'artist'})\n",
    "                    >> map(get_text)\n",
    "                    )\n",
    "                    )\n",
    "current >> get_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}